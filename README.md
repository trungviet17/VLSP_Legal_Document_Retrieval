# VLSP_Legal_Document_Retrieval

## Structure 
```
ğŸ“¦ src
 â”£ ğŸ“‚ benchmark
 â”ƒ â”— ğŸ“œ cal_metric.py        # Calculate performance evaluation metrics
 â”ƒ
 â”£ ğŸ“‚ config
 â”ƒ â”£ ğŸ“œ default.yaml         # Default project configuration
 â”ƒ â”— ğŸ“œ envconfig.py         # Manage API environment variables (OpenAI, Gemini, Groq)
 â”ƒ
 â”£ ğŸ“‚ core
 â”ƒ â”£ ğŸ“‚ chunking
 â”ƒ â”ƒ â”— ğŸ“œ baseline_chunking.py   # Chunking logic for splitting documents
 â”ƒ â”£ ğŸ“‚ db
 â”ƒ â”ƒ â”— ğŸ“œ qdrant.py              # Qdrant vector database connector
 â”ƒ â”— ğŸ“‚ retriever
 â”ƒ   â”— ğŸ“œ baseline_retriever.py  # Baseline retrieval logic
 â”ƒ
 â”£ ğŸ“‚ data                   # Data source 
 â”£ ğŸ“‚ data_processing
 â”ƒ â”— ğŸ“œ eda.ipynb            # Jupyter notebook for data analysis and exploration
 â”ƒ
 â”— ğŸ“‚ utils
    â”£ ğŸ“œ model.py            # Factory for LLM and embedding models
    â”— ğŸ“œ output_parser.py    # Parser for processing language model outputs
```


## How to run baseline 


1. Add data. in vlsp folder, must be add 2 file .json (legal_corpus.json and train.json)
```
cd src
mkdir data/vlsp 
```


2. Run baseline : 
```
python -m venv vlsp-env (python 3.11+)

pip install uv 
uv pip install -r requirements.txt

cd src/scripts 
chmod +x run_baseline.sh --base_path= <your_path> --device=<cuda / cpu>

./run_baseline.sh
```

